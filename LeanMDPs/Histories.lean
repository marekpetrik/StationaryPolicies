import Mathlib.Data.Nat.Defs
import Mathlib.Data.Real.Basic 
import Mathlib.Data.NNReal.Basic

--import Mathlib.Data.Set.Basic
import Mathlib.Data.Finset.Basic
import Mathlib.Data.Finset.Image

import Mathlib.Probability.ProbabilityMassFunction.Basic
--variable (Î± Ïƒ : Type)



/-
In this file we define histories and operations that are related to them. 

* Defines an MDP
* Defines a history, which is a sequence of states and actions
* Defines a histories consistent with a partial sequence of states and actions
* A general randomized history-dependent policy
* The reward and probability of the history, which is used to compute the value function
* Value function for a history as the expected reward

-/

#check PMF
#check Finset
#check Sigma 
#check Multiset.sum
#check Set

#eval 1 âˆˆ [1,2,3] 
#check Membership.mem [1,2,3] 1
 
/--
Represents a history. The state is type Ïƒ and action is type Î±.

The representation of the history is backwards to facilitate the 
application of a policy
-/
inductive Hist (Ïƒ Î± : Type)  : Type where
  | init : Ïƒ â†’ Hist Ïƒ Î±
  | prev : Hist Ïƒ Î± â†’ Î± â†’ Ïƒ â†’ Hist Ïƒ Î±  

/--
The length of the history corresponds to the zero-based step of the decision
-/
def Hist.length {Ïƒ Î± : Type} : Hist Ïƒ Î± â†’ â„•
  | init _ => 0
  | prev h _ _ => HAdd.hAdd (length h) 1

/-- returns the last state of the history -/
def Hist.laststate {Ïƒ Î± : Type} : Hist Ïƒ Î± â†’ Ïƒ
  | init s => s
  | prev _ _ s => s

/-- appends the state and action to the history --/
def Hist.append {Ïƒ Î± : Type} (h : Hist Ïƒ Î±) (as : Î± Ã— Ïƒ) : Hist Ïƒ Î± :=
  Hist.prev h as.fst as.snd


--  Hist.rec (fun _ => 0) (fun hp _ _ _ => 1 + hp.length) h

/--
checks if pre is the prefix of h. This is needed when defining value functions
-/
def isprefix {Ïƒ Î± : Type} [DecidableEq Ïƒ] [DecidableEq Î±] (pre : Hist Ïƒ Î±) (h : Hist Ïƒ Î±) : Prop :=
  match pre, h with
    | Hist.init sâ‚, Hist.init sâ‚‚ => sâ‚ = sâ‚‚
    | Hist.init _, Hist.prev hp _ _ => isprefix pre hp 
    | Hist.prev _ _ _, Hist.init _ => False
    | Hist.prev hâ‚ aâ‚ sâ‚', Hist.prev  hâ‚‚ aâ‚‚ sâ‚‚' => 
        if hâ‚.length > hâ‚‚.length then
            False
        else if hâ‚.length < hâ‚‚.length then
            isprefix pre hâ‚‚
        else
            (aâ‚ = aâ‚‚) âˆ§ (sâ‚' = sâ‚‚') âˆ§ (isprefix hâ‚ hâ‚‚)

open NNReal -- for â„â‰¥0 notation

/--
The Markov decision process definition 

TODO: Consider defining P and r only of the subtypes constructed from 
the Finsets ğ’® and ğ’œ
-/
structure MDP (Ïƒ Î± : Type) : Type where
  /-- states , TODO: consider \McS but causes issues-/
  SS : Finset Ïƒ
  /-- actions, TODO: consider \McA but causes issues  -/
  AA : Finset Î±
  /-- transition probability s, a, s' -/
  -- TODO: should be a probability distribution
  P  : Ïƒ â†’ Î± â†’ Ïƒ â†’ â„â‰¥0
  /-- proof of transition probability --/
  prob : (s : Ïƒ) â†’ (a : Î±) â†’ (âˆ‘ s' âˆˆ SS, P s a s') = 1
  /-- reward function s, a, s' -/
  r  : Ïƒ â†’ Î± â†’ Ïƒ â†’ â„
  /-- initial state -/
  sâ‚€ : Ïƒ
  -- TODO: all these functions need to be only defined for states and actions
  -- should be using a Subtype {s // s âˆˆ states} and Finset attach?

/--
A general randomized history-dependent policy
-/
structure Policy {Ïƒ Î± : Type} (m : MDP Ïƒ Î±) : Type where
  Ï€ : Hist Ïƒ Î± â†’ Î± â†’ â„â‰¥0
  /-- proof that it sums to 1 for all states -/
  prob : (h : Hist Ïƒ Î±) â†’ (âˆ‘ a âˆˆ m.AA, Ï€ h a) = 1

/-- The set of all histories of length T -/
def HistAll {Ïƒ Î± : Type} (T : â„•) := { h : Hist Ïƒ Î± | h.length = T }


-- Need to prove the function used in the construction is injective

/--
Creates new histories from combinations of shorter histories
and states and actions.
-/
def map_hist_as {Ïƒ Î± : Type} : Hist Ïƒ Î± Ã— Î± Ã— Ïƒ â†’ Hist Ïƒ Î± 
  | âŸ¨h, asâŸ© => h.append as
  

def emb_hist_as {Ïƒ Î± : Type} : Hist Ïƒ Î± Ã— Î± Ã— Ïƒ â†ª Hist Ïƒ Î± :=
  {}


/-- 
Set of all policies that follow history pre.
Note that this is just a definition of the set and not a specific instance of the set

The function allhist constructs all histories that satisfy the condition of this set
-/
def PHist {Ïƒ Î± : Type} [DecidableEq Ïƒ] [DecidableEq Î±] 
          (m : MDP Ïƒ Î±) (pre : Hist Ïƒ Î±) (T : â„•) : Finset (Hist Ïƒ Î±)  := 
             if T < pre.length then
               Finset.empty
             else if T = pre.length then
               {pre}
             else
               let AS := Finset.product m.AA  m.SS
               let HAS := Finset.product (PHist m pre (T-1)) AS
               Finset.map (fun has  => (has.fst).append has.snd) HAS 
               
#check Finset.map


/--
Computes the probability of a history
-/
noncomputable def probability {Ïƒ Î± : Type} [DecidableEq Ïƒ] (m : MDP Ïƒ Î±) 
                              (Ï€ : Policy m) : Hist Ïƒ Î± â†’ â„â‰¥0 
      | Hist.init s => if m.sâ‚€ = s then 1. else 0.
      | Hist.prev hp a s' => (m.P hp.laststate a s') * (Ï€.Ï€ hp a) * (probability m Ï€ hp)  

/--
Computes the reward of a history
-/
noncomputable def reward {Ïƒ Î± : Type} (m : MDP Ïƒ Î±) :  Hist Ïƒ Î± â†’ â„ 
    | Hist.init _ => 0.
    | Hist.prev hp a s'  =>  (m.r hp.laststate a s') + (reward m hp)  


/-- show that history probabilities are actually a probability distribution -/
lemma probability_dist {Ïƒ Î± : Type} [DecidableEq Ïƒ] [DecidableEq Î±] 
                       (m : MDP Ïƒ Î±) (pre : Hist Ïƒ Î±) (Ï€ : Policy m) (T : â„•) : 
                       (âˆ‘ h âˆˆ all_hist pre T, (fun h => probability m Ï€) h) = 1 := sorry

/--
Defines the value function for a fixed history-dependent policy
-/
noncomputable 
def value {Ïƒ Î± : Type} [DecidableEq Ïƒ] [DecidableEq Î±] (m : MDP Ïƒ Î±) 
                  (Ï€ : Policy m) (pre : Hist Ïƒ Î±) (T : â„•) : â„ := 
    let ha := all_hist pre T
    âˆ‘ (h âˆˆ ha), (fun h => (probability m Ï€ h) * (reward m h)) h
    -- the charater above is NOT Î£ but is âˆ‘ typed as \sum

#check Finset.sum


/-

TODO:

1. Dynamic program for histories
2. Show that is the policy is Markov then also the value function is Markov

-/
